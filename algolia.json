[{"content":" Quantum Machine Learning Tutorial Paper: Quantum Machine Learning: A Hands-on Tutorial for Machine Learning Practitioners and Researchers Authors: Yuxuan Du1, Xinbiao Wang1, Naixu Guo2, Zhan Yu2, Yang Qian1, Kaining Zhang1, Min-Hsiu Hsieh3, Patrick Rebentrost2, Dacheng Tao1 Institutions: 1College of Computing and Data Science, Nanyang Technological University, Singapore; 2Centre for Quantum Technologies, National University of Singapore, Singapore; 3Hon Hai Research Institute, Taipei, Taiwan Overview This tutorial intends to introduce readers with a background in AI to quantum machine learning (QML) \u0026amp;ndash; a rapidly evolving field that seeks to leverage the power of quantum computers to reshape the landscape of machine learning. For self-consistency, this tutorial covers:\nFoundational principles Representative QML algorithms Potential applications Learning theory and computational complexity Practical code demonstrations Whether you are an AI researcher, a machine learning practitioner, or a computer science student, this resource will equip you with a solid foundation in the principles and techniques of QML. By bridging the gap between classical ML and quantum computing, this tutorial could serve as a useful resource for those looking to engage with quantum machine learning and explore the forefront of AI in the quantum era.\nOrganization Chapter1: Brief introduction of QML. Chapter2: Basics of quantum computing. From classical bits to quantum bits From digital logical circuit to quantum circuit model Quantum read-in and read-out protocols Quantum linear algebra Chapter3: Quantum kernel methods. Classical kernel machines Quantum kernel machines Theoretical foundations of quantum kernel machines Chapter4: Quantum neural networks. Classical neural networks Fault-tolerant quantum perceptron Near-term quantum neural networks Theoretical foundations of quantum neural networks Chapter5: Quantum transformer Classical transformer Fault-tolerant quantum transformer Code …","date":-62135596800,"description":"Text about this post","objectID":"3976528693a0108357f4928017600865","permalink":"http://localhost:1313/","title":"Home"},{"content":"Introduction The advancement of computational power has always been a driving force behind every major industrial revolution. The invention of the modern computer, followed by the central processing unit (CPU), led to the \u0026amp;ldquo;digital revolution\u0026amp;rdquo;, transforming industries through process automation and the rise of information technology. More recently, the development of graphical processing units (GPUs) has powered the era of artificial intelligence (AI) and big data, enabling breakthroughs in areas such as intelligent transportation systems, autonomous driving, scientific simulations, and complex data analysis. However, as we approach the physical and practical limits of Moore\u0026amp;rsquo;s law\u0026amp;mdash;the principle that the number of transistors on a chip doubles approximately every two years\u0026amp;mdash;traditional computing devices like CPUs and GPUs are nearing the end of their scaling potential. The ever-growing demand for computational power, driven by the exponential increase in data and the complexity of modern applications, necessitates new computing paradigms. Among the leading candidates to meet these challenges are quantum computers [@feynman2017quantum], which leverage the unique principles of quantum mechanics such as superposition and entanglement to process information in ways that classical systems cannot, with the potential to revolutionize diverse aspects of daily life.\nOne of the most concrete and direct ways to understand the potential of quantum computers is through the framework of complexity theory [@watrous2008quantum]. Theoretical computer scientists have demonstrated that quantum computers can efficiently solve problems within the $\\mathop{\\mathrm{\\mathsf{BQP}}}$ (Bounded-Error Quantum Polynomial Time) complexity class, meaning these problems can be solved in polynomial time by a quantum computer. In contrast, classical computers are limited to efficiently solving problems within the $\\mathop{\\mathrm{\\mathsf{P}}}$ (Polynomial Time) complexity …","date":-62135596800,"description":"","objectID":"e6c40622f3e32a3ae8baa3511e93b58c","permalink":"http://localhost:1313/chapter1/","title":"Chapter 1 Introduction of QML"},{"content":"In this section, we define quantum bits (qubits) and present the mathematical tools used to describe quantum states. We begin by discussing classical bits and then transition to their quantum counterparts.\nClassical bits In classical computing, a bit is the basic unit of information, which can exist in one of two distinct states: $0$ or $1$. Each bit holds a definite value at any given time. When multiple classical bits are used together, they can represent more complex information. For instance, a set of three bits can represent $2^3=8$ distinct states, ranging from $000$ to $111$.\nQuantum bits (Qubits) Analogous to the role of bit in classical computation, the basic element in quantum computation is the quantum bit (qubit). We start by introducing the representation of single-qubit states and then extend this to two-qubit and multi-qubit states.\nSingle-qubit state. A single-qubit state can be represented by a two-dimensional vector with unit length. Mathematically, a qubit state can be written as $$\\bm{a} = \\begin{bmatrix} \\bm{a}_1 \\\\ \\bm{a}_2 \\end{bmatrix}\\in \\mathbb{C}^2~,$$ where $|\\bm{a}_1|^2+|\\bm{a}_2|^2=1$ satisfies the normalization constraint. Following conventions in quantum theory, we use Dirac notation to represent vectors, i.e., $\\bm{a}$ is denoted by $\\ket{\\bm{a}}$ (named ket) with $$\\ket{\\bm{a}} =\\bm{a}_1\\ket{0}+\\bm{a}_2\\ket{1}~,$$\nwhere $\\ket{0}\\equiv \\bm{e}_0\\equiv \\begin{bmatrix} 1 \\ 0 \\end{bmatrix}$ and $\\ket{1}\\equiv \\bm{e}_1\\equiv \\begin{bmatrix} 0 \\ 1 \\end{bmatrix}$ are two computational (unit) basis states. In this representation, the coefficients $\\bm{a}_1$ and $\\bm{a}_2$ are referred to as amplitudes. The probabilities of obtaining the outcomes $0$ or $1$ upon measurement of the qubit are given by $|\\bm{a}_1|^2$ and $|\\bm{a}_2|^2$, respectively. The normalization constraint ensures that these probabilities always sum to one, as required by the probabilistic nature of quantum mechanics. In addition, the conjugated transpose of $\\bm{a}$, i.e. …","date":-62135596800,"description":"","objectID":"1d2259ea59b7d302e944ec2a08601f10","permalink":"http://localhost:1313/chapter2/1/","title":"Chapter 2.1 From Classical Bits to Quantum Bits"},{"content":"To process quantum states, we need to introduce quantum computation, a fundamental model of which is the quantum circuit model. In this section, we will begin with classical computation and transit to details about the quantum circuit model, including quantum gates, quantum channel, and quantum measurements.\nClassical digital logical circuit Digital logic circuits are the foundational building blocks of classical computing systems. They process classical bits by performing logical operations through logic gates. In this subsection, we introduce the essential components of digital logic circuits and their functionality, followed by a discussion of how these classical circuits relate to quantum circuits.\nLogic gates Logic gates are the basic components of a digital circuit. They take binary inputs, represented as $0$ or $1$, and produce a binary output based on a predefined logical operation. The most common logic gates include:\nNOT Gate: This gate inverts the input bit, i.e., it produces $1$ if the input is $0$, and vice versa. Its truth table is shown in following table\nTruth table of NOT gate\nInput (A) Output (NOT A) 0 1 1 0 AND Gate: Produces an output of $1$ only if both input bits are $1$; otherwise, it outputs $0$. The truth table is shown in following table\nTruth table of AND gate\nInput (A) Input (B) Output (A AND B) 0 0 0 0 1 0 1 0 0 1 1 1 OR Gate: Outputs $1$ if at least one input is $1$. The truth table is shown in following table\nTruth table of OR gate\nInput (A) Input (B) Output (A OR B) 0 0 0 0 1 1 1 0 1 1 1 1 XOR Gate: Produces an output of $1$ if the inputs are different, and $0$ otherwise. The truth table is shown in following table.\nTruth table of XOR gate\nInput (A) Input (B) Output (A XOR B) 0 0 0 0 1 1 1 0 1 1 1 0 These logic gates can be combined in various configurations to build more complex circuits capable of performing arbitrary arithmetic operations.\nCircuit design and universality A classical digital logic circuit is composed of …","date":-62135596800,"description":"","objectID":"90dc3084e9ecab099628cde0bbe3bd9e","permalink":"http://localhost:1313/chapter2/2/","title":"Chapter 2.2 From Digital Logical Circuit to Quantum Circuit Model"},{"content":"The terms quantum read-in and read-out refer to the processes of transferring information between classical systems and quantum systems. These are fundamental steps in the workflow of quantum machine learning, responsible for loading data and extracting results.\nQuantum read-in and read-out pose significant bottlenecks in leveraging quantum computing to address classical computational tasks. As emphasized in [@aaronson2015read], while quantum algorithms can offer exponential speed-ups in specific problem domains, these advantages can be negated if the processes of loading classical data into quantum systems (read-in) or extracting results from quantum systems (read-out) are inefficient. Specifically, the high-dimensional nature of quantum states and the constraints on measurement precision often lead to overheads that scale poorly with problem size. These challenges underscore the importance of optimizing quantum read-in and read-out protocols to realize the full potential of quantum computing. Below is a detailed introduction to quantum read-int and read-out protocols, including the basic concept and several typical algorithms.\nQuantum read-in protocols Quantum read-in refers to the process of encoding classical information into quantum systems that can be manipulated by a quantum computer, which can be regarded as the classical-to-quantum mapping. It acts as a bridge to utilize quantum algorithms to solve classical problems in quantum computing. Here, we will introduce several typical encoding methods, including basis encoding, amplitude encoding, angle encoding, and quantum random access memory.\nBasis encoding Basis encoding is a basic method for processing classical data that can be represented in binary form. Given a classical binary vector $\\bm{x} \\in \\{0, 1\\}^N$, this encoding technique maps the vector directly into a quantum computational basis state as follows:\n$$\\ket{\\psi} = \\ket{\\bm{x}_1,\u0026amp;hellip;,\\bm{x}_N}.$$\nIn this process, $N$ qubits are required to …","date":-62135596800,"description":"","objectID":"826d1f93f20f82f55722d7af5ee44cf1","permalink":"http://localhost:1313/chapter2/3/","title":"Chapter 2.3 Quantum Read-in and Read-out protocols"},{"content":"We next introduce quantum linear algebra, a potent toolbox for designing various FTQC-based algorithms. For clarity, we start with the definition of block encoding, which is about how to implement a matrix on the quantum computer. Based on this, we introduce some basic arithmetic rules for block encodings, like the multiplication, linear combination, and the Hadamard product. Finally, we introduce the quantum singular value transformation method, which enables one to implement functions onto singular values of block-encoded matrices.\nBlock encoding For many computational problems, such as solving linear equations, we need to deal with a non-unitary matrix $A$. However, remember that quantum gates are unitaries. Therefore, if we want to solve these problems on quantum computers, it is essential to consider how to encode the matrix $A$ into a unitary. This challenge can be addressed by the block encoding technique.\nDefinition. Suppose that $A$ is an $N$-qubit operator, $\\alpha, \\varepsilon\\geq 0$ and $a\\in \\mathbb{N}$. Then we say that the $(a+ N)$-qubit unitary $U$ is an $(\\alpha,a,\\varepsilon)$-block-encoding of $A$ if\n$$|A-\\alpha(\\bra{0}^{\\otimes a} \\otimes \\mathbb{I})U(\\ket{0}^{\\otimes a}\\otimes \\mathbb{I})|\\leq \\varepsilon. $$\nHere, $|\\cdot|$ represents the spectral norm, i.e., the largest singular value of the matrix.\nFact. (Block encoding via the linear combination of unitaries (LCU) method, [@gilyenquantum2019]). Suppose that $A$ can be written in the form $$\\begin{aligned} A=\\sum_{k} \\alpha_k U_k, \\end{aligned}$$ where $\\{\\alpha_k\\}$ are real numbers and $U_k$ are some easily prepared unitaries such as Pauli strings. Then, the LCU method allows us to have the access to two unitaries, i.e.,\n$$U_{\\text{SEL}}=\\sum_{k} \\ket{k} \\bra{k}\\otimes U_k,$$\n$$U_{\\text{PREP}}:\\ket{0}\\rightarrow \\frac{1}{\\sqrt{|\\vec{\\alpha}|_1}}\\sum_k \\sqrt{\\alpha_k}\\ket{k},$$\nwhere $\\vec{\\alpha}=(\\alpha_1,\\alpha_2,\\dots)$.\nAfter simple mathematical analysis, one can obtain …","date":-62135596800,"description":"","objectID":"a14ba40c5f1bf107fa4b8f4ef6d8e112","permalink":"http://localhost:1313/chapter2/4/","title":"Chapter 2.4 Quantum Linear Algebra"},{"content":"We end this chapter by discussing the recent advancements in efficiently implementing fundamental components of quantum computing. For clarity, we begin with a brief discussion of advanced quantum read-in and read-out protocols, which are crucial for efficiently loading and extracting classical data in the pipeline of quantum machine learning. Next, we review the latest progress in quantum linear algebra.\nAdvanced quantum read-in protocols Although conventional read-in protocols offer feasible solutions for encoding classical data into quantum computers, they typically face two key challenges that limit their broad applicability for solving practical learning problems. To address these limitations, initial efforts have been made to develop more advanced quantum read-in protocols.\nChallenge I: high demand for quantum resources. Encoding methods like amplitude encoding and basis encoding generally suffer from high quantum resource requirements. While amplitude encoding is highly compact in terms of qubit requirements, the trade-off is the requirement of an exponential number of quantum gates with the data size to prepare an exact amplitude-encoded state. In contrast, while basis encoding can be implemented with a small number of quantum gates, it requires a large number of qubits proportional to the input size. The high demand for either quantum gates or qubit counts makes these basic encoding strategies infeasible for practical use.\nChallenge II: insufficient nonliearity. While quantum mechanics is inherently linear, most practical machine learning models require nonlinearity to capture complex data patterns effectively. Conventional encoding methods like angle encoding introduce some degree of nonlinearity; however, the representational power remains limited due to the linear nature of quantum operations and limited circuit depth.\nFor Challenge I, a practical alternative is the approximate amplitude encoding (AAE) [@nakaji2022approximate]. Instead of implementing …","date":-62135596800,"description":"","objectID":"09b7fcde26861e3f4244d750732d28b9","permalink":"http://localhost:1313/chapter2/5/","title":"Chapter 2.5 Recent Advancements"},{"content":"In this chapter, we introduce the fundamental concepts of quantum computation:\nQuantum states Quantum circuits Quantum measurements Quantum read-in and read-out protocols. Quantum linear algebra. These foundational elements are essential for understanding quantum machine learning algorithms and will be repeatedly referenced throughout the subsequent chapters.\n","date":-62135596800,"description":"","objectID":"d15edf0db850266aaefbd84dd62ddf78","permalink":"http://localhost:1313/chapter2/","title":"Chapter 2 Basis of Quantum Computing"},{"content":"This content of this section corresponds to the Chapter 3.1 of our paper. Please refer to the original paper for more details.\nMotivations for classical kernel machines Before delving into kernel machines, it is essential to first understand the motivation behind kernel methods. In many machine learning tasks, particularly in classification, the goal is to find a decision boundary that best separates different classes of data. When the data is linearly separable, this boundary can be represented as a straight line (in 2D), a plane (in 3D), or a hyperplane (in higher dimensions), as illustrated in the following Figure. Mathematically, given an input space $\\mathcal{X}\\subset \\mathbb{R}^d$ with $d\\ge 1$ and a target or output space $\\mathcal{Y}={+1,-1}$, we consider a training dataset $\\mathcal{D}={(\\bm{x}^{(i)}, {y}^{(i)})}_{i=1}^n \\in (\\mathcal{X} \\times \\mathcal{Y})^n$ where each data point $\\bm{x}^{(i)} \\in \\mathcal{X}$ is associated with a label ${y}^{(i)} \\in \\mathcal{Y}$. For the dataset to be linearly separable, there must exist a vector $\\bm{w} \\in \\mathbb{R}^{d}$ and a bias term $b\\in \\mathbb{R}$ such that $$\\forall i\\in [n], \\quad {y}^{(i)}(\\bm{w}^{\\top} \\cdot \\bm{x}^{(i)}+b)\\ge 0.$$ This means that a hyperplane defined by $(\\bm{\\omega},b)$ can perfectly separate the two classes.\nThroughout the whole tutorial, we interchangeably use the following notations to denote the inner product of two vectors $\\bm{a}$ and $\\bm{b}$, i.e., [complete. $\\langle \\cdot, \\cdot \\rangle$, $\\braket{\\cdot|\\cdot}$, $\\bm{a}\\cdot \\bm{b}$, $\\bm{a}^{\\dagger} \\bm{b}$]\nHowever, in real-world scenarios, data is often not linearly separable, as shown in the Figure(b). The decision boundary required to separate classes may be curved or highly complex. Traditional linear models struggle with such non-linear data because they are inherently limited to creating only linear decision boundaries. This limitation highlights the need for more flexible approaches.\nTo address the challenge of …","date":-62135596800,"description":"","objectID":"bda3b56237465e5b8a5e22ed7b195702","permalink":"http://localhost:1313/chapter3/1/","title":"Chapter 3.1 Classical Kernel"},{"content":"This content of this section corresponds to the Chapter 3.2 of our paper. Please refer to the original paper for more details.\nMotivations for quantum kernel machines To effectively introduce quantum kernel machines, it is essential to recognize the limitations of classical kernel machines. As discussed before, classical kernel machines rely on manually tailored feature mappings, such as polynomials or radial basis functions. However, these mappings may fail to capture the complex patterns behind the dataset. Quantum kernel machines emerge as a promising alternative, as they perform feature mapping using quantum circuits, enabling them to explore exponentially larger feature spaces that are otherwise infeasible for classical computation.\nAnother crucial characteristic of quantum kernels is that they can be effectively implemented on noisy intermediate-scale quantum (NISQ) devices, making them a practical tool for exploring the utility of near-term quantum technologies.\nQuantum feature maps and quantum kernel machines The key difference between quantum kernel machines and classical kernel machines lies in how the feature mapping is performed. In the quantum context, a feature map refers to the injective encoding of classical data $\\bm{x} \\in \\mathbb{R}^d$ into a quantum state $\\ket{\\bm{\\phi}(\\bm{x})}=U(\\bm{x})\\ket{\\phi}$ on an $N$-qubit quantum register, where $U(\\bm{x})$ refers to the physical operation or quantum circuit that depends on the data $\\bm{x}$. This feature map is implemented on a quantum computer and produces quantum states, which are referred to as quantum feature maps.\nDefinition. Given an $N$-qubit quantum system initialized in state $\\ket{\\psi}$, let $\\bm{x}\\in \\mathcal{X} \\subset \\mathbb{R}^d$ be classical data. The quantum feature map is defined as the mapping\n$$ \\phi:\\mathcal{X} \\to \\mathcal{F},$$\n$$\\phi(\\bm{x}) = \\ket{\\bm{\\phi}(\\bm{x})}\\bra{\\bm{\\phi}(\\bm{x})} = \\rho(\\bm{x}),$$\nwhere $\\mathcal{F}$ is the space of complex-valued $2^N \\times 2^N$ …","date":-62135596800,"description":"","objectID":"5811f327c7199b60cbe46d93ba46fd10","permalink":"http://localhost:1313/chapter3/2/","title":"Chapter 3.2 Quantum Kernel Machines"},{"content":"This content of this section corresponds to the Chapter 3.3 of our paper. Please refer to the original paper for more details.\nTheoretical Foundations of Quantum Kernel Machines In this section, we take a step further to explore the theoretical foundations of quantum kernels. Specifically, we focus on two crucial aspects: the expressivity and generalization properties of quantum kernel machines. As shown in Figure 3.4, these two aspects are essential for understanding the potential advantages of quantum kernels over classical learning approaches and their inherent limitations. For ease of understanding, this section emphasizes the fundamental concepts necessary for evaluating the power and limitation of quantum kernels instead of exhaustively reviewing all theoretical results.\nExpressivity of quantum kernel machines Quantum kernels, as discussed before, are constructed by explicitly defining quantum feature mappings. In this context, the expressivity of quantum kernel machines refers to the types of functions that quantum feature mappings can approximate and the kinds of correlations that quantum kernels can effectively model.\nFollowing the conventions of [@gil2024expressivity], we demonstrate that any kernel function can be approximated using finitely deep quantum circuits by showing that the associated feature mapping can also be approximated using quantum circuits. This conclusion rests on two key theoretical foundations: Mercer\u0026amp;rsquo;s feature space construction and the universality of quantum circuits. Together, these principles establish the theoretical feasibility of realizing any kernel function as a quantum kernel.\nIt is important to note that if exact mathematical equality were required, Mercer\u0026amp;rsquo;s construction would demand an infinite-dimensional Hilbert space, which in turn would require quantum computers with infinitely many qubits\u0026amp;mdash;an impractical scenario. However, in practical applications, we are more interested in approximating functions to …","date":-62135596800,"description":"","objectID":"7a52df233f2325a3b78539d1aceae109","permalink":"http://localhost:1313/chapter3/3/","title":"Chapter 3.3 Theoretical Foundations"},{"content":"The foundational concept of using quantum computers to evaluate kernel functions, namely the concept of quantum kernels, was first explored by @schuld2017implementing, who highlighted the fundamental differences between quantum kernels and quantum support vector machines. Building on this, @havlivcek2019supervised and @schuld2019quantum established a connection between quantum kernels and parameterized quantum circuits (PQCs), demonstrating their practical implementation. These works emphasized the parallels between quantum feature maps and the classical kernel trick. Since then, a large number of studies delved into figuring out the potential of quantum kernels for solving practical real-world problems.\nThe recent advancements in quantum kernel machines can be roughly categorized into three key areas: kernel design, theoretical findings, and applications. Specifically, the advances in kernel design focus on addressing challenges such as vanishing similarity and kernel concentration by exploring innovative frameworks. Theoretical studies delve into the limitations and capabilities of quantum kernels, examining factors such as generalization error bounds, noise resilience, and their capacity to demonstrate quantum advantage. Finally, applications of quantum kernels showcase their potential across diverse domains. In the rest of this section, we separately review the existing developments within each of these three branches.\nQuantum kernel design A crucial research line in this field focuses on constructing trainable quantum kernels to maximize performance for specific datasets and problem domains. In particular, traditional quantum kernels, with fixed data embedding schemes, are limited to specific feature representation spaces and often fail to capture the complex and diverse patterns inherent in real-world data. To address this limitation, @lloyd2020quantum explored the construction of task-specific quantum feature maps using measurement theory. Building on this …","date":-62135596800,"description":"","objectID":"db335d62f1f690008670ae3c33134e0f","permalink":"http://localhost:1313/chapter3/4/","title":"Chapter 3.4 Recent Advancements"},{"content":"In this chapter, we provide a step-by-step explanation of the transition from classical kernel machines to quantum kernel machines, covering:\nClassical kernel Quantum kernel Theoretical foundation of quantum kernel machines: expressivity and generalization Recent advancements in quantum kernel machines ","date":-62135596800,"description":"","objectID":"751d6ed410ab6e942d710d6b93048428","permalink":"http://localhost:1313/chapter3/","title":"Chapter 3 Quantum Kernel Methods"},{"content":"This content of this section corresponds to the Chapter 4.1 of our paper. Please refer to the original paper for more details.\nNeural networks [@mcculloch1943logical; @gardner1998artificial; @vaswani2017attention] are computer models inspired by the structure of the human brain, designed to process and analyze complex patterns in data. Originally developed from the concept of neurons connected by weighted pathways, neural networks have become one of the most powerful tools in artificial intelligence [@lecun2015deep]. Each neuron processes its inputs by applying weights and non-linear activations, producing an output that feeds into the next layer of neurons. This structure enables neural networks to learn complex functions during training [@hornik1993some]. For example, given a dataset of images and their labels, a neural network can learn to classify categories, such as distinguishing between cats and dogs, by adjusting its parameters during training. Guided by optimization algorithms such as gradient descent [@amari1993backpropagation], the learning process allows the network to gradually reduce the error between the predicted and actual outputs, allowing it to learn the best parameters for the given task.\nAfter nearly a century of exploration, neural networks have undergone remarkable advancements in both architectures and capabilities. The simplest model, the perceptron [@mcculloch1943logical], laid the foundation by showing how neural networks could learn to separate linearly classifiable categories. Building on this, deeper and more complex networks\u0026amp;mdash;such as multilayer perceptrons (MLPs) [@gardner1998artificial] and transformers [@vaswani2017attention]\u0026amp;mdash;have enabled breakthroughs in tasks such as autonomous driving and content generation.\nPerceptron The perceptron model, first introduced by [@mcculloch1943logical], is widely regarded as a foundational structure in artificial neural networks, inspiring architectures ranging from convolutional neural …","date":-62135596800,"description":"","objectID":"8775999e4ae2417c175e3cf1747d0a47","permalink":"http://localhost:1313/chapter4/1/","title":"Chapter 4.1 Classical Neural Networks"},{"content":"This content of this section corresponds to the Chapter 4.2 of our paper. Please refer to the original paper for more details.\nThe primary aim of advancing quantum machine learning is to harness the computational advantages of quantum mechanics to enhance performance across various learning tasks. These advantages manifest in several ways, including reduced runtime, lower query complexity, and improved sample efficiency compared to classical models. A notable example of this is the quantum perceptron model [@kapoor2016quantum]. As a [FTQC]{.sans-serif}-based QML algorithm grounded in the Grover search, quantum perceptron offers a quadratic improvement in the query complexity during the training over its classical counterpart. For comprehensiveness, we first introduce the Grover search algorithm, followed by a detailed explanation of the quantum perceptron model.\nGrover search Grover search [@grover1996fast] provides runtime speedups for unstructured search problems, which have broad applications in cryptography, quantum machine learning, and constraint satisfaction problems. Unlike classical search methods that require $\\mathcal{O}(d)$ queries for a dataset with $d$ entries, Grover\u0026amp;rsquo;s algorithm can identify the target element with high probability using only $\\mathcal{O}(\\sqrt{d})$ queries to a quantum oracle. Consequently, quantum algorithms incorporating Grover search have the potential to achieve a quadratic speedup over classical approaches.\nIn general, a search task can be abstracted as a function $f({x})$ such that $f({x})=1$ if ${x}$ belongs to the solution set of the search problem, and $f({x})=0$ otherwise. We consider a dataset consisting of $d=2^N$ elements, where each element is represented by the quantum state $|{x}\u0026amp;gt;$ with $x=0,1,\\cdots,d-1$. In this process, two key quantum oracles are introduced. The first oracle, $U_0 = 2\\ket{0}\\bra{0}-\\mathbb{I}_{d}$, applies a phase shift of $e^{i\\pi}=-1$ to all quantum states except $|0\u0026amp;gt;$, which remains …","date":-62135596800,"description":"","objectID":"4904dd220d7a15b5c38a326655477c5d","permalink":"http://localhost:1313/chapter4/2/","title":"Chapter 4.2 Fault-tolerant Quantum Perceptron"},{"content":"This content of this section corresponds to the Chapter 4.3 of our paper. Please refer to the original paper for more details.\nFollowing recent experimental breakthroughs in superconducting quantum hardware architectures [@arute2019quantum; @acharya2024quantum; @abughanem2024ibm; @gao2024establishing], researchers have devoted considerable effort to developing and implementing quantum machine learning algorithms optimized for current and near-term quantum devices [@wang2024comprehensive]. Compared to fault-tolerant quantum computers, these devices face two primary limitations: quantum noise and circuit connectivity constraints. Regarding quantum noise, state-of-the-art devices have single-qubit gate error rates of $10^{-4} \\sim 10^{-3}$ and two-qubit gate error rates of approximately $10^{-3} \\sim 10^{-2}$ [@abughanem2024ibm; @gao2024establishing]. The coherence time is around $10^2 \\mu s$ [@acharya2024quantum; @abughanem2024ibm; @gao2024establishing], primarily limited by decoherence in noisy quantum channels. Regarding circuit connectivity, most superconducting quantum processors employ architectures that exhibit two-dimensional connectivity patterns and their variants [@acharya2024quantum; @abughanem2024ibm; @gao2024establishing]. Gate operations between non-adjacent qubits must be executed through intermediate relay operations, leading to additional error accumulation. To address these inherent limitations, the near-term quantum neural network (QNN) framework has been proposed. Specifically, near-term QNNs are designed to perform meaningful computations using quantum circuits of limited depth.\nGeneral framework In this section, we introduce the architecture of a basic near-term QNN. As illustrated in Figure 4.4, a basic QNN consists of three components: the input, the model circuit, and the measurement.\nInput. The near-term QNN uses quantum states as input data. QNNs can process both classical and quantum data. Specifically, the input states $\\rho_{ in}$ may be …","date":-62135596800,"description":"","objectID":"d0ca83948fb179f10a154c2c3e92541b","permalink":"http://localhost:1313/chapter4/3/","title":"Chapter 4.3 Near-term quantum neural networks"},{"content":"This content of this section corresponds to the Chapter 4.4 of our paper. Please refer to the original paper for more details.\nAs a machine learning (ML) model, the primary goal of quantum neural networks (QNNs) is to make accurate predictions on unseen data. Achieving this goal depends on three key factors: expressivity, generalization ability, and trainability. A thorough understanding of these factors is crucial for evaluating the potential advantages and limitations of QNNs compared to classical ML models. Instead of providing an exhaustive review of all theoretical results, this section focuses on near-term QNNs, emphasizing key conceptual insights into their capabilities and limitations.\nExpressivity and generalization of quantum neural networks The expressivity and generalization are deeply interconnected within the framework of statistical learning theory for understanding the prediction ability of any learning model. To better understand these two terms in the context of quantum neural networks, we first review the framework of empirical risk minimization (ERM), which is a popular framework for analyzing these abilities in statistical learning theory.\nConsider the training dataset $\\mathcal{D} = \\{(\\bm{x}^{(i)},\\bm{y}^{(i)})\\} \\in \\mathcal{X} \\times \\mathcal{Y}$ sampled independentaly from an unknown distribution $\\mathcal{P}$, a learning algorithm $\\mathcal{A}$ aims to use the dataset $\\mathcal{D}$ to infer a hypotheis $h_{\\bm{\\theta}^*}: \\mathcal{X}\\to \\mathcal{Y}$ from the hypothesis space $\\mathcal{H}$ that could accurately predict all labels of $\\bm{x}\\in \\mathcal{X}$ following the distribution $\\mathcal{P}$. Under the framework of ERM, this is equivalent to identifying an optimal hypothesis in $\\mathcal{H}$ minimizing the expected risk\nwhere $\\ell(\\cdot,\\cdot)$ refers to the per-sample loss predefined by the learner. Unfortunately, the inaccessible distribution $\\mathcal{P}$ forbids us to assess the expected risk directly. In practice, $\\mathcal{A}$ …","date":-62135596800,"description":"","objectID":"182b084c361459c0bb8b77eac19d6d58","permalink":"http://localhost:1313/chapter4/4/","title":"Chapter 4.4 Theoretical Foundations of QNNs"},{"content":"Quantum neural networks (QNNs) have emerged as a prominent paradigm in quantum machine learning, demonstrating potential in both discriminative and generative learning tasks. For discriminative tasks, QNNs utilize high-dimensional Hilbert spaces to efficiently capture and represent complex intrinsic relationships. In generative tasks, QNNs leverage variational quantum circuits to generate complex probability distributions that may exceed the capabilities of classical models. While these approaches share common learning strategies, they each introduce unique challenges and opportunities in terms of model design, theoretical exploration, and practical implementation. In the remainder of this section, we briefly review recent advances in QNNs. Interested readers can refer to @ablayev2019quantum [@li2022recent; @massoli2022leap] for a more comprehensive review.\nDiscriminative learning with QNN QNNs for discriminative tasks have emerged as one of the most active research areas in quantum machine learning, demonstrating potential advantages in feature representation and processing efficiency. The quantum learning approach leverages the high-dimensional Hilbert space and quantum parallelism to potentially handle complex classification boundaries more effectively than classical neural networks. Research has shown particular promise in handling datasets with inherent quantum properties and problems where quantum entanglement can be meaningfully exploited [@huang2022quantum].\nModel designs In the realm of quantum discriminative models, researchers have developed various quantum neural architectures. In general, variational quantum classifiers [@havlivcek2019supervised; @mitarai2018quantum] could employ parameterized quantum circuits for classification tasks. Subsequently, quantum convolutional neural networks [@cong2019quantum] are designed for processing structured data. Hybrid quantum-classical architectures [@arthur2022hybrid] are proposed to combine quantum layers with …","date":-62135596800,"description":"","objectID":"c5eecde642ff8c6e0224f182beecae47","permalink":"http://localhost:1313/chapter4/5/","title":"Chapter 4.5 Recent Advancements"},{"content":"In this chapter, we provide a systematic overview of quantum neural networks, covering:\nThe structure and function of classical neural networks Fault-tolerant quantum neural networks Near-term quantum neural networks Theoretical foundations of QNN ","date":-62135596800,"description":"","objectID":"89a057afe085f55c8d799ebb2a3256d3","permalink":"http://localhost:1313/chapter4/","title":"Chapter 4 Quantum Neural Networks"},{"content":"This content of this section corresponds to the Chapter 5.1 of our paper. Please refer to the original paper for more details.\nThe transformer architecture is designed to predict the next token in a sequence by leveraging sophisticated neural network components. Its modular design\u0026amp;mdash;including residual connections, layer normalization, and feed-forward networks (FFNs) as introduced in Chapter 4.1\u0026amp;mdash;makes it highly scalable and customizable. This versatility has enabled its successful application in large-scale foundation models across diverse domains, including natural language processing, computer vision, reinforcement learning, robotics, and beyond.\nThe full architecture of Transformer is illustrated in Figure 5.1. Note that while the original paper by @vaswani2017attention introduced both encoder and decoder components, contemporary large language models primarily adopt decoder-only architectures, which have demonstrated superior practical performance.\n","date":-62135596800,"description":"","objectID":"df6ecdcbc01d676d337405341a21527d","permalink":"http://localhost:1313/chapter5/1/","title":"Chapter 5.1 Classical Transformer"},{"content":"This content of this section corresponds to the Chapter 5.2 of our paper. Please refer to the original paper for more details.\nIn this section, we move on to show an end-to-end transformer architecture implementable on a quantum device, which includes all the key building blocks introduced in Chapter 5.1, and a discussion of the potential runtime speedups of this quantum model. In particular, here we focus on the inference process in which a classical Transformer has already been trained and is queried to predict the single next token.\nRecall that in Chapter 5.1, we suppose that the three parameterized matrices in the self-attention mechanism have the same size, i.e., $W_q, W_k, W_v \\in \\mathbb{R}^{d \\times d}$. Besides, the input sequence $S$ and the matrix returned by the attention block $G^{\\text{soft}}$ has the size $\\ell \\times d$. Here, we further suppose the length of the sentence and the dimension of hidden features exponentially scale with $2$, i.e., $\\ell=2^N$ and $\\log d\\in \\mathbb{N^+}$. This setting aligns with the scaling of quantum computing, making it easier to understand. For other cases, padding techniques can be applied to expand the matrix and vector dimensions to conform to this requirement.\nSince the runtime speedups depend heavily on the capabilities of the available input oracles, it is essential to specify the input oracles used in the quantum Transformer before detailing the algorithms. For the classical Transformers, the memory access to the inputs such as the sentence and the query, key, and value matrices is assumed. In the quantum version, we assume the access of several matrices via block encodings introduced in Chapter 2.4.\nAssumption 5.2.1. Following the explicit form of the single-head and single-layer Transformer, there are five parameterized weight matrices, i.e., $W_q$, $W_k$, $W_v \\in \\mathbb{R}^{d\\times d}$ in the attention block, as well as $M_1\\in \\mathbb R^{d\u0026amp;rsquo; \\times d}$ and $M_2 \\in \\mathbb R^{d \\times d\u0026amp;rsquo;}$ in …","date":-62135596800,"description":"","objectID":"e173b1c77c47c4919bec1a93177e600d","permalink":"http://localhost:1313/chapter5/2/","title":"Chapter 5.2 Fault-tolerant Quantum Transformer"},{"content":"This content of this section corresponds to the Chapter 5.3 of our paper. Please refer to the original paper for more details.\nAs Theorem 5.1 shows, the quantum transformer uses ${\\mathcal{\\widetilde{O}}}(d N^2 \\alpha_s\\alpha_w)$ times the input block encodings, where $\\alpha_s$ and $\\alpha_w$ are encoding factors that significantly influence the overall complexity. We obtain this final complexity on the basis of the following considerations: for one-single layer transformer architecture, it includes one self-attention, one feed-forward network, and two residual connection with layer normalization, corresponding to the encoder-only or decoder-only structure. Starting from the input assumption, for the index $j\\in [\\ell]$, we first construct the block encoding of self-attention matrix. This output can be directly the input of the quantum residual connection and layer normalization, which output is a state encoding. The state encoding can directly be used as the input of the feed-forward network. Finally, we put the output of the feed-fordward network, which is a state encoding, into the residual connection block. This is possible by noticing that state encoding is a specific kind of the block encoding. Multiplying the query complexity of these computational blocks, one can achieve the result. The detailed analysis of runtime is referred to @guo2024quantumlinear2024\nBy analyzing naive matrix multiplication, the runtime of classical single-layer transformer inference is $\\mathcal{O}(\\ell d + d^2)$, where $d$ is the embedding dimension and $\\ell=2^N$ is the input sequence length.\nIn this section, we provide a combined analytical and numerical analysis to explore the potential of a quantum speedup in time complexity.\nRecall that the encoding factor $\\alpha$ is lower bounded by the spectral norm of a block-encoded matrix $A$, i.e., $\\alpha \\geq \\left|A\\right|$. Given access to quantum Random Access Memory (QRAM) and a quantum data structure [@lloyd2014quantum; …","date":-62135596800,"description":"","objectID":"e8446de9acfa0a076dcc2fb00cfed6ee","permalink":"http://localhost:1313/chapter5/3/","title":"Chapter 5.3 Runtime Analysis with Quadratic Speedups"},{"content":"Transformer architecture has profoundly revolutionized AI and has broad impacts. As classical computing approaches its physical limitations, it is important to ask how we can leverage quantum computers to advance Transformers with better performance and energy efficiency. Besides the fault-tolerant quantum Transformers, multiple works are advancing this frontier from various perspectives.\nOne aspect is to design novel quantum neural network architectures introduced in Chapter 4 with the intuition from the Transformer, especially the design of the self-attention block. In particular, @li2023quantumselfattentionneuralnetworks proposes the quantum self-attention neural networks and verifies their effectiveness with the synthetic data sets of quantum natural language processing. There are several follow-up works along this direction [@Cherrat_2024; @evans2024learningsasquatchnovelvariational; @widdows2024quantumnaturallanguageprocessing].\nAnother research direction is exploring how to utilize quantum processors to advance certain parts of the transformer architecture. Specifically, @gao2023fastquantumalgorithmattention considers how to compute the self-attention matrix under sparse assumption and shows a quadratic quantum speedup. @liu2024quantumcircuitbasedcompressionperspective harnesses quantum neural networks to generate weight parameters for the classical model. In addition, @liu2024towards devises a quantum algorithm for the training process of large-scale neural networks, implying an exponential speedup under certain conditions.\nDespite the progress made, several important questions remain unresolved. Among them, one key challenge is devising efficient methods to encode classical data or parameters onto quantum computers. Currently, most quantum algorithms can only implement one or at most constant layers of Transformers [@guo2024quantumlinear2024; @liao2024gptquantumcomputer; @khatri2024quixerquantumtransformermodel] without quantum tomography. Are there …","date":-62135596800,"description":"","objectID":"3e8cc2ec453dcb717062d95c02ed8f51","permalink":"http://localhost:1313/chapter5/4/","title":"Chapter 5.4 Recent Advancements"},{"content":"In this chapter, we provide an overview of quantum transformer, including:\nMechanism of Transformers How to construct a quantum Transformer on a fault-tolerant quantum computer The runtime of quantum transformers Recent Advancements ","date":-62135596800,"description":"","objectID":"eb6713ccb36b7e8d2499d94fcd902d6b","permalink":"http://localhost:1313/chapter5/","title":"Chapter 5 Quantum Transformer"},{"content":"","date":-62135596800,"description":"","objectID":"b3827c9680770e0f03c58ccf7bc48d61","permalink":"http://localhost:1313/code/","title":"Code Examples"},{"categories":["Quantum Neural Network"],"content":"In this tutorial, we show how to utilize QNN to handle discriminative tasks based on PennyLane library. Specifically, we aim to implement a quantum binary classifier for the Wine dataset. The primary pipeline includes following steps:\nLoad and preprocess the Wine dataset. Implement a quantum read-in protocol to load classical data into quantum states. Construct a parameterized quantum circuit model to process the input. Train the whole circuit and test. We begin by importing all related libraries:\nimport sklearn import sklearn.datasets import pennylane as qml from pennylane import numpy as np from pennylane.optimize import AdamOptimizer import matplotlib.pyplot as plt We then prepare the Wine dataset for classification task. For simplicity, we focus on the the first two class of the whole Wine dataset. There are 13 attributes determining the origin of wines, where the value of each attribute ranges differently. The normizalization preprocessing is applied to this dataset to re-scale the attribute value to the range of $[0, \\pi]$. Meantime, the label is re-mapped from ${0,1}$ to ${-1,1}$ for alignment with value range of the read-out result of quantum circuit model, which will be introduced later. For later generation test of quantum classifier, we fairly split the dataset into training data and test data.\ndef load_wine(split_ratio = 0.5): feat, label = sklearn.datasets.load_wine(return_X_y=True) # normalization feat = np.pi * (feat - np.min(feat, axis=0, keepdims=True)) / np.ptp(feat, axis=0, keepdims=True) index_c0 = label == 0 index_c1 = label == 1 label = label * 2 - 1 n_c0 = sum(index_c0) n_c1 = sum(index_c1) X_train = np.concatenate((feat[index_c0][:int(split_ratio*n_c0)], feat[index_c1][:int(split_ratio*n_c1)]), axis=0) y_train = np.concatenate((label[index_c0][:int(split_ratio*n_c0)], label[index_c1][:int(split_ratio*n_c1)]), axis=0) X_test = np.concatenate((feat[index_c0][int(split_ratio*n_c0):], feat[index_c1][int(split_ratio*n_c1):]), axis=0) y_test = …","date":-62135596800,"description":"An introduction to implement a quantum neural network for classification.","objectID":"e9a8defd059a46d6c2028521d0d6850e","permalink":"http://localhost:1313/code/classifier/","title":"Quantum Classifier"},{"content":"Code Demonstration This section provides code implementations for key techniques introduced earlier, including quantum read-in strategies and block encoding, to give readers the opportunity to practice and deepen their understanding.\nRead-in implementations This subsection demonstrates toy examples of implementing data encoding methods in quantum computing, as discussed in earlier sections. Specifically, we cover basis encoding, amplitude encoding, and angle encoding. These examples aim to provide readers with hands-on experience in applying quantum data encoding techniques.\nBasis encoding PennyLane provides built-in support for basis encoding through its BasisEmbedding function. Below is the Python code demonstrating the basis encoding for the integer 6.\nimport pennylane as qml dev = qml.device(\u0026amp;#34;default.qubit\u0026amp;#34;, range(3)) @qml.qnode(dev) def circuit(x): qml.BasisEmbedding(x, range(3)) return qml.state() # Call the function circuit(6) Amplitude encoding PennyLane offers built-in support for amplitude encoding via the AmplitudeEmbedding function. Below is a Python example demonstrating amplitude encoding for a randomly generated complex vector.\nimport pennylane as qml import numpy as np # Number of qubits n_qubits = 8 # Define a quantum device with 8 qubits dev = qml.device(\u0026amp;#34;default.qubit\u0026amp;#34;, wires=n_qubits) @qml.qnode(dev) def circuit(x): qml.AmplitudeEmbedding(features=x, wires=range(n_qubits), normalize=True, pad_with=0.) return qml.state() # Generate a random complex vector of length 2^n_qubits x_real = np.random.normal(loc=0, scale=1.0, size=2**n_qubits) x_imag = np.random.normal(loc=0, scale=1.0, size=2**n_qubits) x = x_real + 1j * x_imag # Execute the circuit to encode the vector as a quantum state circuit(x) Angle encoding PennyLane provides built-in support for angle encoding via the AngleEmbedding function. Below is a Python example demonstrating angle encoding for a randomly generated real vector.\nimport pennylane as qml import numpy as np # …","date":-62135596800,"description":"","objectID":"8c3a402f4e193cb5df0b1d0129069693","permalink":"http://localhost:1313/code/data-encode/","title":"Data Encoding"},{"content":"In this tutorial, we will train a SVM classifier with a quantum kernel on the MNIST dataset. The basic pipeline is implemented with following steps:\nLoad the dataset. Define the quantum feature mapping. Construct the quantum kernel. Construct and train the SVM. We begin by importing all related libraries:\nimport pennylane as qml from sklearn.datasets import fetch_openml from sklearn.decomposition import PCA from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.svm import SVC from sklearn.metrics import accuracy_score import numpy as np import matplotlib.pyplot as plt We then load the MNIST dataset. Here we focus on two classes of 3 and 6, leading to a binary classification problem. PCA is firstly applied to reduce the feature dimension of images in MNIST to reduce the required number of qubits to encode this classifcal feature. The compressed features are then normalized to match the periodicity of the quantum feature mapping used later.\ndef load_mnist(n_qubit): # Load MNIST dataset from OpenML mnist = fetch_openml(\u0026amp;#39;mnist_784\u0026amp;#39;, version=1) X, y = mnist.data, mnist.target # Filter out the digits 3 and 6 mask = (y == \u0026amp;#39;3\u0026amp;#39;) | (y == \u0026amp;#39;6\u0026amp;#39;) X_filtered = X[mask] y_filtered = y[mask] # Convert labels to binary (0 for digit 3 and 1 for digit 6) y_filtered = np.where(y_filtered == \u0026amp;#39;3\u0026amp;#39;, 0, 1) # Apply PCA to reduce the feature dimension pca = PCA(n_components=n_qubit) X_reduced = pca.fit_transform(X_filtered) # Normalize the input feature scaler = StandardScaler().fit(X_reduced) X_scaled = scaler.transform(X_reduced) # Split into training and testing sets X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_filtered, test_size=0.2, random_state=42) return X_train, X_test, y_train, y_test We use the angle embedding as the quantum feature mapping method. The quantum kernel is therefore implemented as:\nn_qubit = 8 dev = qml.device(\u0026amp;#39;default.qubit\u0026amp;#39;, wires=n_qubit) …","date":-62135596800,"description":"","objectID":"17c04e109fbcdc7a5e454e45a7a4a29b","permalink":"http://localhost:1313/code/kernel-mnist/","title":"Classification on MNIST"},{"categories":["Quantum Neural Network"],"content":"In this tutorial, we demonstrate how to implement a quantum patch GAN introduced in Chapter xxx for the generation of hand-written digit of five. The whole pipeline includes following steps:\nLoad and pre-process the dataset Build the classical discriminator Build the quantum generator Train the quantum patch GAN Visualize the generated images We begin by importing required libraries:\nimport torch import torch.nn as nn import torch.optim as optim from torch.utils.data import Dataset, DataLoader import numpy as np import matplotlib.pyplot as plt import pennylane as qml import math Step 1: Dataset Preparation We will use the Optical Recognition of Handwritten Digits dataset, where each data point represents an $8\\times 8$ grayscale image. Let’s start by defining a custom dataset class to load and process the data.\nclass OptdigitsData(Dataset): def __init__(self, data_path, label): \u0026amp;#34;\u0026amp;#34;\u0026amp;#34; Dataset class for Optical Recognition of Handwritten Digits. \u0026amp;#34;\u0026amp;#34;\u0026amp;#34; super().__init__() self.data = [] with open(data_path, \u0026amp;#39;r\u0026amp;#39;) as f: for line in f.readlines(): if int(line.strip().split(\u0026amp;#39;,\u0026amp;#39;)[-1]) == label: # Normalize image pixel values from [0,16) to [0, 1) image = [int(pixel)/16 for pixel in line.strip().split(\u0026amp;#39;,\u0026amp;#39;)[:-1]] image = np.array(image, dtype=np.float32).reshape(8, 8) self.data.append(image) self.label = label def __len__(self): return len(self.data) def __getitem__(self, index): return torch.from_numpy(self.data[index]), self.label After defining the dataset class, we visualize a few examples to better understand the structure of the dataset.\ndef visualize_dataset(data_path): \u0026amp;#34;\u0026amp;#34;\u0026amp;#34; Visualizes the dataset by displaying examples for each digit label. \u0026amp;#34;\u0026amp;#34;\u0026amp;#34; plt.figure(figsize=(10, 5)) for i in range(10): plt.subplot(1, 10, i + 1) data = OptdigitsData(data_path, label=i) plt.imshow(data[0][0], cmap=\u0026amp;#39;gray\u0026amp;#39;) plt.title(f\u0026amp;#34;Label: {i}\u0026amp;#34;) plt.axis(\u0026amp;#39;off\u0026amp;#39;) plt.tight_layout() plt.show() …","date":-62135596800,"description":"An introduction to implement a quantum GAN.","objectID":"88c30ed0ee46a7c253474e4596695e21","permalink":"http://localhost:1313/code/patch-qgan/","title":"Quantum Patch GAN"},{"content":"We explain how self-attention works with a simple concrete example. Consider a short sequence of three words: \u0026amp;ldquo;The cat sleeps\u0026amp;rdquo;.\nFirst, we convert each word into an embedding vector. For this toy example, we use very small 4-dimensional embeddings:\nThe = [1, 0, 1, 0] cat = [0, 1, 1, 1] sleeps = [1, 1, 0, 1] In self-attention, each word needs to \u0026amp;ldquo;attend\u0026amp;rdquo; to all other words in the sequence. This happens through three key steps using learned weight matrices ($W_q$, $W_k$, $W_v$) to transform the embeddings into queries, keys, and values. When we multiply our word embeddings by these matrices, we get\nimport numpy as np # Input tokens (3 tokens, each with 3 features) S = np.array([ [1, 0, 1, 0], # for \u0026amp;#34;The\u0026amp;#34; [0, 1, 1, 1], # for \u0026amp;#34;cat\u0026amp;#34; [1, 1, 0, 1] # for \u0026amp;#34;sleeps\u0026amp;#34; ]) # Initialize weights for Query, Key, and Value (4x3 matrices) W_q = np.array( [ [0.2, 0.4, 0.6, 0.8], [0.1, 0.3, 0.5, 0.7], [0.9, 0.8, 0.7, 0.6], [0.5, 0.4, 0.3, 0.2], ] ) W_k = np.array( [ [0.1, 0.3, 0.5, 0.7], [0.6, 0.4, 0.2, 0.1], [0.8, 0.9, 0.7, 0.6], [0.2, 0.1, 0.3, 0.4], ] ) W_v = np.array( [ [0.3, 0.5, 0.7, 0.9], [0.6, 0.4, 0.2, 0.1], [0.8, 0.9, 0.7, 0.6], [0.5, 0.4, 0.3, 0.2], ] ) # Compute Query, Key, and Value matrices Q = S @ W_q K = S @ W_k V = S @ W_v Next, we compute attention scores by multiplying $Q$ and $K^T$, then applying softmax.\n# Compute scaled dot-product attention d = Q.shape[1] # Feature dimension attention_scores = Q @ K.T / np.sqrt(d) def softmax(x): \u0026amp;#34;\u0026amp;#34;\u0026amp;#34;Compute softmax values for each set of scores in x.\u0026amp;#34;\u0026amp;#34;\u0026amp;#34; return np.exp(x) / np.sum(np.exp(x), axis=1, keepdims=True) attention_weights = softmax(attention_scores) The attention weight would be: $$\\text{softmax}\\left(\\frac{Q \\cdot K^T}{\\sqrt{4}}\\right) = \\begin{bmatrix} 0.324 \u0026amp;amp; 0.467 \u0026amp;amp; 0.209\\ 0.305 \u0026amp;amp; 0.515 \u0026amp;amp; 0.180\\ 0.346 \u0026amp;amp; 0.432 \u0026amp;amp; 0.222 \\end{bmatrix}.$$ The final output captures how each word relates to every other word in the sentence. In this …","date":-62135596800,"description":"a toy example of a classical Transformer.","objectID":"fc58cacb23f98f6f5292e8c5441407e3","permalink":"http://localhost:1313/code/transformer/","title":"Tranformer"},{"content":"This tutorial provides a comprehensive introduction to the latest developments in quantum machine learning, specifically designed for readers with expertise in machine learning.\nWhile a deep understanding of quantum physics is not required, having the following foundational knowledge will enhance your ability to engage with the material:\nLinear algebra Fundamentals of machine learning Python Software Environment The code examples in this tutorial have been tested on the following software platform:\nPython==3.9.6 PennyLane==0.34.0 scikit-learn==1.4.2 ","date":-62135596800,"description":"","objectID":"dfae1d937010a359c06f3a1a5f0b3f0a","permalink":"http://localhost:1313/getting-started/","title":"Getting Started"},{"content":"Welcome to the Resources page, where you can find valuable materials to aid your journey in Quantum Machine Learning. Below is a curated list of textbooks, software and hardware platforms, lecture notes, and other open-source libraries.\nTextbooks Quantum Computation and Quantum Information\nAuthor: Michael A. Nielsen and Isaac L. Chuang\nThis is one of the most widely used textbooks in the field of quantum computing. It covers the fundamental concepts of quantum mechanics, quantum computation, and quantum algorithms in depth. A must-read for anyone getting started with quantum computing.\nThe Theory of Quantum Information\nAuthor: John Watrous\nThis is a book on the mathematical theory of quantum information, focusing on a formal presentation of definitions, theorems, and proofs. It is primarily intended for graduate students and researchers having some familiarity with quantum information and computation.\nDive into Deep Learning\nAuthor: Aston Zhang, Zack C. Lipton, Mu Li and Alex J. Smola\nThis book covers foundational deep learning techniques and practical applications with math, discussions and code written in Python.\nOpen-source Libraries PennyLane\nPennyLane is a powerful open-source software library for quantum machine learning, quantum computing, and quantum chemistry. It integrates well with popular ML frameworks like PyTorch and TensorFlow, allowing users to combine quantum circuits with classical neural networks.\nQiskit\nQiskit is an open-source quantum computing framework from IBM. It is one of the most popular tools for building and simulating quantum circuits, and also includes a library for quantum machine learning. Qiskit’s machine learning module allows users to implement quantum-enhanced algorithms easily.\nTensorFlow Quantum\nTensorFlow Quantum is an open-source library for quantum machine learning, built on top of TensorFlow. It offers tools for training quantum models and combining classical and quantum data to build hybrid quantum-classical models.\nCirq …","date":-62135596800,"description":"","objectID":"74f7fb04a75e766307d398251c369a21","permalink":"http://localhost:1313/resources/","title":"Resources"}]